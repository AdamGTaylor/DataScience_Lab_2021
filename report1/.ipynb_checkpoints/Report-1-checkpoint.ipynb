{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report 1 - Localising workflow\n",
    "\n",
    "## Localisation\n",
    "\n",
    "The first step was to obtain the data avaliable only by creating an account at https://ghrc.nsstc.nasa.gov/home/. This was easy, so I looked at how to download data from them, for which they porvided a single simple line for wget:\n",
    "\n",
    "<pre><code class=\"lang-python\"><span class=\"hljs-title\"> wget --user YOUR-Earthdata-USERNAME --ask-password --auth-no-challenge --no-check-certificate -i PATH-TO-GHRC_URLs.txt </span>\n",
    "</code></pre>\n",
    "\n",
    "This is rather easy to use, but for Windows, GNU-wget has to be installed and after that, the wget.exe has to added to path variable. After accomplising all of this, I got an error prompt stating that the flag --ask-password could not be understood by wget, thus I had to switch to a Linux based device, which, as expected, downloaded the data from the site very easily. It just took me 1.5 hours to get the files and move them to the other device fo calculations.\n",
    "\n",
    "This was quite the endervour!\n",
    "\n",
    "The localised workflow only needsa Jupyter Notebook to be installed through Anaconda and I can start my work now!\n",
    "\n",
    "\n",
    "## Producing Simplified Output\n",
    "\n",
    "While its still ongoing, the simplified output needs to contain time and location of the lightning flash. The comparison of the description and the actual HDF files is somewhat hard, which meant that I had to download the other type of datas too, including the netCDF. The netCDF handling is well docmented on the official site, but I grabbed the HDF4 files, and kooplex has them too, thus I am sticking with what I have now!\n",
    "\n",
    "The simplified output should contain only the most meaningful data about the lightnings: time, flash, coords. In the end, the produced simplified output should loo like this:\n",
    "\n",
    "| TIME | FLASH | LONG. | LAT. | FILE TIME WIDTH |\n",
    "|------|-------|-------|------|-----------------|\n",
    "|  ... |  ...  |  ...  | ...  |       ...       |\n",
    "\n",
    "This file will be uploaded and/or given out to reproduce the heatmap. Right now, I till have to play with the hdf files, because they are not that well documented. \n",
    "\n",
    "### Issues with localised workflow\n",
    "\n",
    "The problem with localised workflow is that there has to be some version control and backup avaliable in case of any circumstance causing the unavaliability of the localised workflow (like outage). This means that I will utilize github anf kooplex and the same time!\n",
    "\n",
    "<font size=\"4\"> This report is very short due to the lot of error handlings and time consuming processes behind it... </font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
